{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "320882aa-f3d3-41a2-b1cb-a11ae903b80a",
   "metadata": {},
   "source": [
    "# Image Data Capture\n",
    "\n",
    "Data from Execution Rocks Weather Buoy is unreliable. NWS doesn't store the data in whatever form. For our purposes we could use the data anyway as we are only interested in realtime readings not modelling reliability. The buoy access point is supposed to supply this data but we can't access it. So I have to try to OCR the fixed data locations an begin to build our own database.  This sheet is a model for the capture.\n",
    "\n",
    "The website is: `https://lisicos.uconn.edu/stn_exrx.php`\n",
    "\n",
    "The image is: `<img src=\"https://clydebank.dms.uconn.edu/exrx_wxSens2.png\" alt=\"Execution Rocks Weather Panel\" border=\"1\" style=\"border: 1px solid #999999;\">`\n",
    "\n",
    "<img src=\"https://clydebank.dms.uconn.edu/exrx_wxSens2.png?4\" alt=\"Execution Rocks Weather Panel\" border=\"1\" style=\"border: 1px solid #999999;\">\n",
    "*Hint: change the number after the '?' to force a refresh.*\n",
    "\n",
    "The steps are to first build and test the components of the tool to extract the data and then develop an object for doing this on the fly.\n",
    "The current plan is to create a class that does this and to run it once every 15 minutes to collect the data in a circular buffer 24 hours long that will then be used to fuel an existing graphing tool for windspeed and direction. There is a lot of other information we can collect, like wave height, which may also be included in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4fd9439-05c6-47ab-aea5-fb0fe2746578",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "General imports needed.\n",
    "\"\"\"\n",
    "# foundational libraries\n",
    "from datetime import datetime, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "import pytz  # may need to migrate to ZoneInfo\n",
    "import requests\n",
    "import logging\n",
    "\n",
    "# OCR tools\n",
    "import pytesseract\n",
    "# Bridge to cli tool. Need to install tesseract CLI engine in the OS\n",
    "\n",
    "# Managing images\n",
    "from PIL import Image\n",
    "\n",
    "# Data management\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6805a839-0472-4281-90d5-7502153ee0a1",
   "metadata": {},
   "source": [
    "## Build and test components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78237235-cc2f-472d-b494-b26cb3e57d64",
   "metadata": {},
   "source": [
    "### Image Retrieval\n",
    " - `get_and_store_png` is good for any of the NERACOOS images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e3fe43d-3fdb-49c0-9156-83fffdd2189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the method we use to retrieve the image\n",
    "\n",
    "\"\"\"\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_and_store_png(url, filename=\"image.png\"):\n",
    "    \"\"\"\n",
    "        :param url: URL to retrieve the image (expect a png)\n",
    "        :param url: filename to store the image.  We may implement a memory store option.\n",
    "        :return:    filepath (or maybe PIL object?)\n",
    "    \"\"\"\n",
    "    # 1. Retrieve the image\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful (HTTP 200)\n",
    "    if response.status_code == 200:\n",
    "        # 2. Store to disk for a second step\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        return filename  # Return path to the stored file\n",
    "    else:\n",
    "        raise Exception(f\"Failed to retrieve image. Status code: {response.status_code}\")\n",
    "\n",
    "# Example usage\n",
    "# image_url = \"https://clydebank.dms.uconn.edu/exrx_wxSens2.png\"\n",
    "# stored_path = get_and_store_png(image_url)\n",
    "# Second step: use 'stored_path' to process the image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9be7bb9-2c75-4fe2-a386-d6020b9335bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Process the image using the **P**ython **I**mage **L**ibrary\n",
    "tools extracting and preparing the pieces of the image for OCR recognition.\n",
    " - `preprocess_for_ocr` tweaks the image to insure more reliable OCR\n",
    " - `extract_regions` extract the desired region for OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "180d85c0-2189-4f5c-bf4a-73411e65e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def preprocess_for_ocr(croppedImage):\n",
    "    \"\"\"\n",
    "    Improve the image for the OCR process.\n",
    "    :param croppedImage: an image object retrieved from the cropping process.\n",
    "    :return: adapted image for OCR step\n",
    "    \"\"\"\n",
    "    # 1. Convert to Grayscale ('L' mode in Pillow)\n",
    "    gray_crop = croppedImage.convert('L')\n",
    "    \n",
    "    # 2. Resize: Tesseract needs clear, large characters. \n",
    "    # Upscaling by 2x or 3x often fixes issues with small regions.\n",
    "    w, h = gray_crop.size\n",
    "    upscaledImage = gray_crop.resize((w * 2, h * 2), Image.Resampling.LANCZOS)\n",
    "    \n",
    "    # 3. Optional: Invert if text is light on a dark background\n",
    "    # Tesseract expects dark text on a light background.\n",
    "    # upscaled = ImageOps.invert(upscaled) \n",
    "    return upscaledImage\n",
    "\n",
    "def extract_regions(image_path, regions):\n",
    "    \"\"\"\n",
    "    Extracts multiple rectangular regions from a PNG.  Again, we store the result \n",
    "    on disk but maybe we can get away with memory?\n",
    "    :param image_path: Path to the retrieved PNG file.\n",
    "    :param regions: List of 4-tuples (left, upper, right, lower) coordinates.\n",
    "    :return: List of cropped Image objects.\n",
    "    \"\"\"\n",
    "    extracted_images = []\n",
    "    \n",
    "    with Image.open(image_path) as img:\n",
    "        # Standardize for OCR: convert to RGB and remove transparency\n",
    "        img = img.convert(\"RGB\") \n",
    "        \n",
    "        for i, box in enumerate(regions):\n",
    "            # box = (left, upper, right, lower)\n",
    "            # Example: (10, 10, 100, 50) extracts a 90x40 pixel area\n",
    "            crop = preprocess_for_ocr(img.crop(box))\n",
    "            \n",
    "            # Optional: Store locally for debugging or the second step\n",
    "            crop.save(f\"region_{i}.png\")\n",
    "            extracted_images.append(crop)\n",
    "            \n",
    "    return extracted_images\n",
    "\n",
    "# Example usage:\n",
    "# Coordinates for two different fields on your document\n",
    "# target_areas = [(50, 100, 200, 150), (300, 400, 450, 480)]\n",
    "# croppedImages = extract_regions(\"image.png\", target_areas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1967796-31e4-45d5-a152-78296fb29ab9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### displayImages\n",
    "A quick and dirty tool to display processed images prior to OCR. Intended for debugging\n",
    " - `display_extracted_regions`\n",
    " - Also demos how we can do this without a program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c980b02-b0a7-4680-b3f8-376ce48e8bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_extracted_regions(croppedImages, titles=None):\n",
    "    \"\"\"\n",
    "    Displays a list of PIL image crops in a Matplotlib grid.\n",
    "    :param croppedImages: a list of cropped images \n",
    "    :param title: optional titles.\n",
    "    \"\"\"\n",
    "    num_crops = len(croppedImages)\n",
    "    # Create a grid: 1 row, multiple columns\n",
    "    fig, axes = plt.subplots(1, num_crops, figsize=(15, 5))\n",
    "    \n",
    "    # Handle case with only one crop (axes won't be an array)\n",
    "    if num_crops == 1:\n",
    "        axes = [axes]\n",
    "        \n",
    "    for i, crop in enumerate(croppedImages):\n",
    "        # print(f\"\\tDBG: {i:02d}, {titles[i]}: {len(crop)}\")\n",
    "        axes[i].imshow(crop, cmap='gray')\n",
    "        axes[i].axis('off')  # Hide pixel coordinates for OCR preview\n",
    "        if titles:\n",
    "            axes[i].set_title(titles[i])\n",
    "            \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage with crops from your previous step\n",
    "# display_extracted_regions(croppedImages, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66197e12-dafd-43ba-ae9d-561aa18887f4",
   "metadata": {},
   "source": [
    "<!-- <img src=\"./region0.png\" align=\"left\">  <img src=\"./region1.png\" align=\"right\">\n",
    "<img src=\"./region2.png\" align=\"left\">  <img src=\"./region3.png\" align=\"right\">\n",
    "<img src=\"./region4.png\" align=\"left\">  <img src=\"./region5.png\" align=\"right\"> -->\n",
    "<!-- ```\n",
    "titles = [\"windSpeedKtsAvg\", \"windSpeedKtsGst\", \"windDirTrue\",\n",
    "           \"windSpeedMphAvg\", \"windSpeedMphGst\",\n",
    "           \"airTempFar\", \"airTempCent\",\n",
    "           \"baromPresTorr\", \"baromPresmBar\", \n",
    "           \"dateString\"]\n",
    "``` -->\n",
    "|c1|c2|c3|\n",
    "|:-:|:-:|:-:|\n",
    "|\"windSpeedKtsAvg\"|\"windSpeedKtsGst\"|\"windDirTrue\"|\n",
    "|![windSpeedKtsAvg](region_0.png)|![windSpeedKtsGst](region_1.png)|![windDirTrue](region_2.png)|\n",
    "|\"windSpeedMphAvg\"|\"windSpeedMphGst\"|\n",
    "|![windSpeedMphAvg](region_3.png)|![windSpeedMphGst](region_4.png)||\n",
    "|\"airTempFar\"|\"airTempCent\"||\n",
    "|![airTempFar](region_5.png)|![airTempCent](region_6.png)||\n",
    "|\"baromPresTorr\"|\"baromPresmBar\"||\n",
    "|![baromPresTorr](region_7.png)|![baromPresmBar](region_8.png)||\n",
    "|\"dateString\"|||\n",
    "|![dateString](region_9.png)|||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e9cd84-1a77-4abc-ad23-98944ca92d03",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Manually define the regions of interest\n",
    "Open a copy of the NERACOOS image in Gimp and define the rectangles that encapsulate \n",
    "the data we want to capture. Eventually this will find its way into a common data structure.\n",
    "\n",
    " - Curate the capture regions and data.\n",
    " - Develop the data structure for containing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d28704-1fa1-4ef1-9116-f563e3b9af4b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Preliminary exercise. final values are redefined below.\n",
    "windSpeedKtsAvg = (21, 307, 63, 327)   #kts\n",
    "windSpeedKtsGst = (116, 307, 158, 327) #kts\n",
    "windSpeedMphAvg = (21, 334, 63, 351)   #mph\n",
    "windSpeedMphGst = (116, 334, 158, 351) #mph\n",
    "windDirTrue     = (230, 320, 287, 339) #deg True\n",
    "airTempFar      = (410, 169, 471, 188) #degFarenheit\n",
    "airTempCent     = (409, 221, 471, 238) #degCentegrade\n",
    "baromPresTorr   = (391, 415, 449, 434) #barm in mmHg\n",
    "baromPresmBar   = (467, 415, 537, 434) #barm in mBar\n",
    "dateString      = (100, 64, 294, 78) #dateString\n",
    "\n",
    "regions = [windSpeedKtsAvg, windSpeedKtsGst, windDirTrue,\n",
    "           windSpeedMphAvg, windSpeedMphGst,\n",
    "           airTempFar, airTempCent,\n",
    "           baromPresTorr, baromPresmBar, dateString]\n",
    "\n",
    "titles = [\"windSpeedKtsAvg\", \"windSpeedKtsGst\", \"windDirTrue\",\n",
    "           \"windSpeedMphAvg\", \"windSpeedMphGst\",\n",
    "           \"airTempFar\", \"airTempCent\",\n",
    "           \"baromPresTorr\", \"baromPresmBar\", \n",
    "           \"dateString\"]\n",
    "\n",
    "# crops = extract_regions(\"image.png\", regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4251ff-8f33-4b4b-98da-c605bff07ec0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Do the OCR of the regions and test the tweaking sercrets\n",
    "\n",
    " - `ocr_numerals_only` limit our recognition to floats with or without minus signs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9eddd220-4a75-4055-8399-55cf92a27f0c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted values: ['6.9', '10.5', '288', '7.9', '12.0', '23.2', '4.9', '29.87', '1011.64', '113000.01']\n",
      "windSpeedKtsAvg:\t       6.9\n",
      "windSpeedKtsGst:\t      10.5\n",
      "windDirTrue:\t     288.0\n",
      "windSpeedMphAvg:\t       7.9\n",
      "windSpeedMphGst:\t      12.0\n",
      "airTempFar:\t      23.2\n",
      "airTempCent:\t       4.9\n",
      "baromPresTorr:\t      29.9\n",
      "baromPresmBar:\t    1011.6\n",
      "dateString:\t  113000.0\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "# Need to install tesseract\n",
    "\n",
    "def ocr_numerals_only(image_crops):\n",
    "    \"\"\"\n",
    "    Processes image crops to extract only numbers and decimal points.\n",
    "    :param image_crops: List of PIL Image objects (from previous step).\n",
    "    :return: List of extracted numeric strings.\n",
    "    \"\"\"\n",
    "    # Configuration breakdown:\n",
    "    # --psm 6: Assume a single uniform block of text (good for small crops)\n",
    "    # tessedit_char_whitelist: Restrict characters to digits and dot\n",
    "    custom_config = r'--psm 6 -c tessedit_char_whitelist=-0123456789.'\n",
    "    \n",
    "    extracted_data = []\n",
    "    for crop in image_crops:\n",
    "        # Perform OCR\n",
    "        text = pytesseract.image_to_string(crop, config=custom_config)\n",
    "        # Clean up whitespace/newlines\n",
    "        extracted_data.append(text.strip())\n",
    "        \n",
    "    return extracted_data\n",
    "\n",
    "# Example usage\n",
    "numeric_values = ocr_numerals_only(crops)\n",
    "print(f\"\\tDBG: Extracted values: {numeric_values}\")\n",
    "for i, valueStr in enumerate(numeric_values):\n",
    "    val = float(valueStr)\n",
    "    print(f\"\\tDBG: {titles[i]}:\\t{val:10.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e47b17-81e6-428f-bb98-21834e722bf4",
   "metadata": {},
   "source": [
    "Quick test to see if we can capture the date string as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "220dd4c2-fb78-4ccc-b6cd-1bcdb9c4c5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11:30:00 PM EST, Thu Jan 01\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytesseract.image_to_string(crops[-1], config=r'--psm 6 -c tessedit_char_whitelist=-0123456789,:\\ APMSunMonTueEdThuFriSatJanFebMarAprMayJunJulAugSepOctNovDec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcb989c-8c29-4573-a176-308ab7f2533e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Pulling it all together\n",
    "We need to install the following on the Raspberry Pi:\n",
    "```bash\n",
    "# install \n",
    "sudo pip install PIL\n",
    "\n",
    "# Update package lists\n",
    "sudo apt update\n",
    "\n",
    "# Install the Tesseract OCR engine\n",
    "sudo apt install -y tesseract-ocr\n",
    "\n",
    "# Install Python dependencies\n",
    "pip3 install pytesseract Pillow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53786709-8f34-4b20-b555-c741af67384b",
   "metadata": {},
   "source": [
    "## Build the class\n",
    " - organize the desired fields into a dictioanary\n",
    " - collect the above methods into a class.\n",
    " - refactor the methods for efficiency and maintenace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b647c80-03ec-4d19-8916-01d16c01d9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Quick review: NERACOOS weather buoys are managed by the Univ. of Ct. Bridgeport. They have invested, \n",
    "    heavily in a package (software and hardware) that provides real-time data on wind, waves and water \n",
    "    quality for LI Sound. We are most interested in two buoys which are close by to our harbor:\n",
    "    Execution Rocks [exrx] and Western LI Sound [wlis]. The devices with their software can deliver csv lists\n",
    "    of their systems but it would appear that the servers that present the data are not set up for this or\n",
    "    not properly installed.  Since trying to access this infomation doesn't resolve to a permissions error\n",
    "    or a no-authorized response but just a blunt php crash I am assuming the later.\n",
    "\n",
    "    Our only option is to read the data from the .png graphical screens that are presented on their\n",
    "    website. Fortunately this is pretty straightforward. In addition the data is only updated every 15 minutes\n",
    "    for the Wind information and 20min for wave information.  Pulling data once every 10min seems like an\n",
    "    easy lift.\n",
    "\"\"\"\n",
    "\n",
    "# Global defintion of no data.\n",
    "NaN = float('nan')\n",
    "\n",
    "# image URIs for Wind information\n",
    "execrocksWind_url = \"https://clydebank.dms.uconn.edu/exrx_wxSens2.png\"  # Execution rocks\n",
    "westernLIWind_url = \"https://clydebank.dms.uconn.edu/wlis_wxSens1.png\"  # Western Long Island\n",
    "\n",
    "# dictionary of locations within the image of the data we want.\n",
    "windSources = {\n",
    "    'WindSpeedAvg [kts]': {'bounds':( 21, 307,  63, 327), 'value': NaN,}, #kts\n",
    "    'WindSpeedGst [kts]': {'bounds':(116, 307, 158, 327), 'value': NaN }, #kts\n",
    "    'WindSpeedAvg [mph]': {'bounds':( 21, 334,  63, 351), 'value': NaN }, #mph\n",
    "    'WindSpeedGst [mph]': {'bounds':(116, 334, 158, 351), 'value': NaN }, #mph\n",
    "    'WindSpeedAvg [m/s]': {'bounds':(21, 358, 63, 375),   'value': NaN }, #m/s\n",
    "    'WindSpeedGst [m/s]': {'bounds':(116, 358, 158, 375), 'value': NaN }, #m/s\n",
    "    'WindDir [°]':        {'bounds':(230, 320, 287, 339), 'value': NaN }, #deg True\n",
    "    'AirTemp [°F]':       {'bounds':(410, 169, 471, 188), 'value': NaN }, #degFarenheit\n",
    "    'AirTemp [°C]':       {'bounds':(409, 221, 471, 238), 'value': NaN }, #degCentegrade\n",
    "    'BaromPres [mmHg]':   {'bounds':(391, 415, 449, 434), 'value': NaN }, #barm in mmHg\n",
    "    'BaromPres [mB]':     {'bounds':(467, 415, 537, 434), 'value': NaN }, #barm in mBar\n",
    "    'DewPoint [°F]':      {'bounds':(505, 322, 552, 341), 'value': NaN }, #dewpoint degFarenheit\n",
    "    'DewPoint [°C]':      {'bounds':(563, 322, 605, 341), 'value': NaN }, #dewPoint degCentegrade\n",
    "    'RelHum [%]':         {'bounds':(391, 323, 448, 341), 'value': NaN }, #rel. humidity\n",
    "    'WindTimestamp':      {'bounds':(100,  64, 294,  78), 'value': NaN }, #dateString for reading\n",
    "    'WindSpeedM24 [kt]':  {'bounds':(112, 412, 150, 435), 'value': NaN }, #kts max in last 24hrs\n",
    "    'WindDirM24 [°]':     {'bounds':(271, 412, 300, 433), 'value': NaN }, #deg True in last 24hrs\n",
    "    'WindTimeM24':        {'bounds':(114, 433, 299, 454), 'value': NaN }, #dateString of 24Hr Max\n",
    "}\n",
    "\n",
    "# image URIs for Wave information\n",
    "westernLIWaves_url = \"https://clydebank.dms.uconn.edu/wlis_wavs.png\" \n",
    "execrocksWaves_url = \"https://clydebank.dms.uconn.edu/exrx_wavs.png\"\n",
    "\n",
    "# dictionary of locations within the image of the data we want.\n",
    "waveSources = {\n",
    "    'WaveHgtSig [ft]':    {'bounds':( 68, 329, 112, 346), 'value': NaN,}, #ft\n",
    "    'WaveHgtMax [ft]':    {'bounds':(168, 329, 212, 346), 'value': NaN }, #ft\n",
    "    'WaveHgtSig [m]':     {'bounds':( 68, 353, 112, 371), 'value': NaN,}, #m\n",
    "    'WaveHgtMax [m]':     {'bounds':(168, 353, 212, 371), 'value': NaN }, #m\n",
    "    'WaveDir [°]':        {'bounds':(292, 322, 347, 340), 'value': NaN }, #degT\n",
    "    'WavPerAvg [s]':      {'bounds':(479, 193, 539, 211), 'value': NaN }, #sec\n",
    "    'WavPerDom [s]':      {'bounds':(479, 251, 539, 269), 'value': NaN }, #sec\n",
    "    'WaveTimestamp':      {'bounds':(100,  64, 294,  78), 'value': NaN }, #dateString for reading\n",
    "    'WaveHgt24 [ft]':     {'bounds':(169, 413, 207, 433), 'value': NaN }, #kts max in last 24hrs\n",
    "    'WaveDirM24 [°]':     {'bounds':(327, 412, 354, 433), 'value': NaN }, #deg True in last 24hrs\n",
    "    'WavePerAvgM24 [s]':  {'bounds':(169, 442, 207, 433), 'value': NaN }, #deg True in last 24hrs\n",
    "    'WaveperDomM24 [s]':  {'bounds':(542, 442, 574, 433), 'value': NaN }, #deg True in last 24hrs\n",
    "    'WaveTimeM24':        {'bounds':(169, 433, 363, 455), 'value': NaN }, #dateString of 24Hr Max  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05922dd8-936e-4470-a17a-c2a724e5b21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WindSpeedAvg [kts]',\n",
       " 'WindSpeedGst [kts]',\n",
       " 'WindSpeedAvg [mph]',\n",
       " 'WindSpeedGst [mph]',\n",
       " 'WindSpeedAvg [m/s]',\n",
       " 'WindSpeedGst [m/s]',\n",
       " 'WindDir [°]',\n",
       " 'AirTemp [°F]',\n",
       " 'AirTemp [°C]',\n",
       " 'BaromPres [mmHg]',\n",
       " 'BaromPres [mB]',\n",
       " 'DewPoint [°F]',\n",
       " 'DewPoint [°C]',\n",
       " 'RelHum [%]',\n",
       " 'WindTimestamp',\n",
       " 'WindSpeedM24 [kt]',\n",
       " 'WindDirM24 [°]',\n",
       " 'WindTimeM24']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(windSources.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c52a14e-ea26-40c5-b7a3-63379f62d2f7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "class BuoyDataCapture:\n",
    "\n",
    "    # Source for image to decode\n",
    "    sourceURL = \"\"\n",
    "    # Placeholder for results\n",
    "    dataDict = {}\n",
    "    # temporary holder for downloaded image (maybe keep in memory?)\n",
    "    filename  = \"image.png\"\n",
    "    # Tesseract works best when limiting the characters to look for.\n",
    "    ocrLimits = { # 0 decode for numbers\n",
    "        'numberlike': r'--psm 6 -c tessedit_char_whitelist=-0123456789.',\n",
    "                  # 1 decode for date\n",
    "        'datelike':   r'--psm 6 -c tessedit_char_whitelist=-0123456789,:\\ APMSunMonTueWedThuFriSatJanFebMarAprMayJunJulAugSepOctNovDecESTGMT',\n",
    "    }\n",
    "\n",
    "    def __init__(self, sourceImageURL, dataExtraction):\n",
    "        \"\"\"\n",
    "        Initialize the class\n",
    "        :param sourceImageURL: Where we get the original image. The last part of the path will be a valid .png file name.\n",
    "        :param dataExtraction: The structure (see above) that delineates the bounds we are trying to capture along with a place to store the result.\n",
    "        \"\"\"\n",
    "        logging.debug(f\"Instantiating {self.__class__}\")\n",
    "        logging.debug(f\"URI: {sourceImageURL}\")\n",
    "        logging.debug(f\"DataKeys: {dataExtraction.keys()}\")\n",
    "\n",
    "        self.sourceURL = sourceImageURL\n",
    "        self.dataDict = dataExtraction\n",
    "        self.filename = sourceImageURL.split(\"/\")[-1]\n",
    "        self.df = pd.DataFrame()\n",
    "        self.df = pd.DataFrame(windSources.keys())\n",
    "        self.df.index.name = 'Timestamp'\n",
    "\n",
    "    def fetch_image(self, filename=None):\n",
    "        \"\"\"\n",
    "        retrieve the png and store to a file\n",
    "        :param filename:  An optional name for the capture.\n",
    "        \"\"\"\n",
    "        # 1. Retrieve the image  n.b. add a \"?###\" random number to sidestep local caching\n",
    "        response = requests.get(self.sourceURL + f\"?{np.random.randint(1000)}\")\n",
    "        logging.debug(f\"Fetching {self.sourceURL} {response.status_code}\")\n",
    "\n",
    "        # 2. Change the stored filename if provided\n",
    "        if filename != None:\n",
    "            self.filename = filename\n",
    "        \n",
    "        # Check if the request was successful (HTTP 200)\n",
    "        if response.status_code == 200:\n",
    "            # 3. Store to disk for a second step, the image is not large, maybe keep in memory?\n",
    "            with open(self.filename, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "        else:\n",
    "            raise Exception(f\"Failed to retrieve image. Status code: {response.status_code}\")\n",
    "\n",
    "    def preprocess_for_ocr(self, croppedImage):\n",
    "        \"\"\"\n",
    "        Improve the image for the OCR process. Mostly used in internally.\n",
    "        :param croppedImage: an image object retrieved from the cropping process.\n",
    "        :return: adapted image for OCR step\n",
    "        \"\"\"\n",
    "        logging.debug(f\"Preprocessing image\")\n",
    "        # 1. Convert to Grayscale ('L' mode in Pillow)\n",
    "        gray_crop = croppedImage.convert('L')\n",
    "        \n",
    "        # 2. Resize: Tesseract needs clear, large characters. \n",
    "        # Upscaling by 2x or 3x often fixes issues with small regions.\n",
    "        w, h = gray_crop.size\n",
    "        upscaledImage = gray_crop.resize((w * 2, h * 2), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        # 3. Optional: Invert if text is light on a dark background\n",
    "        # Tesseract expects dark text on a light background.\n",
    "        # upscaled = ImageOps.invert(upscaled) \n",
    "        return upscaledImage\n",
    "    \n",
    "    def ocr_numbers_only(self, image_crop, ocrCharacterLimit):\n",
    "        \"\"\"\n",
    "        Processes a cropped image to extract only numbers and decimal points.\n",
    "        :param image_crop: A single cropped image.\n",
    "        :param ocrCharacterLimit: A set of characters to use when trying to decode the image\n",
    "        :return: The value for the image.\n",
    "        \"\"\"\n",
    "        logging.debug(f\"Convert image to a number\")\n",
    "        # Configuration breakdown:\n",
    "        # --psm 6: Assume a single uniform block of text (good for small crops)\n",
    "        # tessedit_char_whitelist: Restrict characters to digits and dot\n",
    "        return float(self._ocr_values(image_crop, self.ocrLimits['numberlike']))\n",
    "\n",
    "    def ocr_dates_only(self, image_crop):\n",
    "        \"\"\"\n",
    "        Processes image crops to extract only numbers and decimal points.\n",
    "        :param image_crops: List of PIL Image objects (from previous step).\n",
    "        :return: List of extracted numeric strings.\n",
    "        \"\"\"\n",
    "        logging.debug(f\"Convert image to a date\")\n",
    "        # Configuration breakdown:\n",
    "        # --psm 6: Assume a single uniform block of text (good for small crops)\n",
    "        # tessedit_char_whitelist: Restrict characters to digits and dot\n",
    "        datetext = self._ocr_values(image_crop, self.ocrLimits['datelike']) + f\", {datetime.now().year}\"\n",
    "        logging.debug(f\"scanned text: {datetext}\")\n",
    "\n",
    "        # Decoding the date can be tricky. Though the buoys are connected via cell their clocks can be wildly off\n",
    "        dateOK = False\n",
    "        if not dateOK:\n",
    "            try:\n",
    "                date = datetime.strptime(data, \"%I:%M:%S %p %Z, %a %b %d, %Y\")  # even though it captures the EST it is naive\n",
    "                dateOK = True\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if not dateOK:\n",
    "            try:\n",
    "                data = datetime.strptime(data, \"%I:%M:%S %p %Z, %a%b %d, %Y\")  # even though it captures the EST it is naive\n",
    "                dateOK = True\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if not dateOK:\n",
    "            try:\n",
    "                date = datetime.strptime(data, \"%I:%M:%S %p %Z, %b %d, %Y\")  # even though it captures the EST it is naive\n",
    "                dateOK = True\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        tz = pytz.timezone('US/Eastern')\n",
    "        date = data.replace(tzinfo=tz)\n",
    "        logging.debug(f\"{date}\")\n",
    "        return date  # date should be timezone aware.\n",
    "    \n",
    "    def _ocr_values(self, image_crop, ocrCharacterLimit):\n",
    "        \"\"\"\n",
    "        Processes a cropped image to extract only numbers and decimal points.\n",
    "        :param image_crop: A single cropped image.\n",
    "        :param ocrCharacterLimit: A set of characters to use when trying to decode the image\n",
    "        :return: The value for the image.\n",
    "        \"\"\"\n",
    "        text = pytesseract.image_to_string(image_crop, config=ocrCharacterLimit)\n",
    "        # Clean up whitespace/newlines\n",
    "        return text.strip()        \n",
    "        \n",
    "    def extract_regions(self):\n",
    "        \"\"\"\n",
    "        Extracts multiple rectangular regions from a PNG.  Again, we store the result \n",
    "        on disk but maybe we can get away with keeping in memory?\n",
    "        :param image_path: Path to the retrieved PNG file.\n",
    "        :param regions: List of 4-tuples (left, upper, right, lower) coordinates.\n",
    "        :return: List of cropped Image objects.\n",
    "        \"\"\"\n",
    "        # extracted_images = []\n",
    "        \n",
    "        with Image.open(self.filename) as img:\n",
    "            # Standardize for OCR: convert to RGB and remove transparency\n",
    "            img = img.convert(\"RGB\")\n",
    "\n",
    "            for key, item in self.dataDict.items():\n",
    "                logging.debug(f\"key: {key}, bounds:{item['bounds']} {key.find(\"Time\")}\")\n",
    "                croppedImage = self.preprocess_for_ocr(img.crop(item['bounds']))\n",
    "\n",
    "                if key.find(\"Time\")>-1:\n",
    "                    # Decoding the date can be tricky. Though the buoys are connected via cell their clocks can be wildly off.\n",
    "                    data = self.ocr_dates_only(croppedImage, self.ocrLimits['datelike'])\n",
    "                    data += \", {datetime.now().year}\"\n",
    "\n",
    "                    #ATTN: When testing this on Jan 02, 2026 the buoy's clock was 2hrs fast. This may be corrected later.\n",
    "                    if datetime.now(pytz.timezone('US/Eastern')) < data:\n",
    "                        # The buoy reports the wrong time every now and again probably 2 hours off. 1/7/26 Seems to have been fixed.\n",
    "                        logging.debug(\"Fixed time\")\n",
    "                        data = data - timedelta(hours=2)\n",
    "                    else:\n",
    "                        logging.debug(\"Time is OK\")\n",
    "                else:\n",
    "                    try:\n",
    "                        data = self.ocr_numbers_only(croppedImage)\n",
    "                        data = float(data)\n",
    "                    except:\n",
    "                        data = np.nan\n",
    "                item['value'] = data\n",
    "\n",
    "    def getDict(self):\n",
    "        return self.dataDict\n",
    "\n",
    "    def getDF(self):\n",
    "        return self.df\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.dataDict(key)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3c9f6ac-b8f1-4ad5-a18f-2bb38eb7269c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 22:30:13,886 - DEBUG - Instantiating <class '__main__.BuoyDataCapture'>\n",
      "2026-01-09 22:30:13,890 - DEBUG - URI: https://clydebank.dms.uconn.edu/exrx_wxSens2.png\n",
      "2026-01-09 22:30:13,892 - DEBUG - DataKeys: dict_keys(['WindSpeedAvg [kts]', 'WindSpeedGst [kts]', 'WindSpeedAvg [mph]', 'WindSpeedGst [mph]', 'WindSpeedAvg [m/s]', 'WindSpeedGst [m/s]', 'WindDir [°]', 'AirTemp [°F]', 'AirTemp [°C]', 'BaromPres [mmHg]', 'BaromPres [mB]', 'DewPoint [°F]', 'DewPoint [°C]', 'RelHum [%]', 'WindTimestamp', 'WindSpeedM24 [kt]', 'WindDirM24 [°]', 'WindTimeM24'])\n",
      "2026-01-09 22:30:13,902 - DEBUG - Starting new HTTPS connection (1): clydebank.dms.uconn.edu:443\n",
      "2026-01-09 22:30:14,666 - DEBUG - https://clydebank.dms.uconn.edu:443 \"GET /exrx_wxSens2.png?81 HTTP/1.1\" 200 58697\n",
      "2026-01-09 22:30:14,712 - DEBUG - Fetching https://clydebank.dms.uconn.edu/exrx_wxSens2.png 200\n",
      "2026-01-09 22:30:14,814 - DEBUG - STREAM b'IHDR' 16 13\n",
      "2026-01-09 22:30:14,816 - DEBUG - STREAM b'sRGB' 41 1\n",
      "2026-01-09 22:30:14,819 - DEBUG - STREAM b'gAMA' 54 4\n",
      "2026-01-09 22:30:14,821 - DEBUG - STREAM b'pHYs' 70 9\n",
      "2026-01-09 22:30:14,823 - DEBUG - STREAM b'IDAT' 91 58590\n",
      "2026-01-09 22:30:14,861 - DEBUG - key: WindSpeedAvg [kts], bounds:(21, 307, 63, 327) -1\n",
      "2026-01-09 22:30:14,863 - DEBUG - Preprocessing image\n",
      "2026-01-09 22:30:14,868 - DEBUG - key: WindSpeedGst [kts], bounds:(116, 307, 158, 327) -1\n",
      "2026-01-09 22:30:14,871 - DEBUG - Preprocessing image\n",
      "2026-01-09 22:30:14,875 - DEBUG - key: WindSpeedAvg [mph], bounds:(21, 334, 63, 351) -1\n",
      "2026-01-09 22:30:14,878 - DEBUG - Preprocessing image\n",
      "2026-01-09 22:30:14,884 - DEBUG - key: WindSpeedGst [mph], bounds:(116, 334, 158, 351) -1\n",
      "2026-01-09 22:30:14,886 - DEBUG - Preprocessing image\n",
      "2026-01-09 22:30:14,891 - DEBUG - key: WindSpeedAvg [m/s], bounds:(21, 358, 63, 375) -1\n",
      "2026-01-09 22:30:14,893 - DEBUG - Preprocessing image\n",
      "2026-01-09 22:30:14,898 - DEBUG - key: WindSpeedGst [m/s], bounds:(116, 358, 158, 375) -1\n",
      "2026-01-09 22:30:14,900 - DEBUG - Preprocessing image\n",
      "2026-01-09 22:30:14,903 - DEBUG - key: WindDir [°], bounds:(230, 320, 287, 339) -1\n",
      "2026-01-09 22:30:14,906 - DEBUG - Preprocessing image\n",
      "2026-01-09 22:30:14,912 - DEBUG - key: AirTemp [°F], bounds:(410, 169, 471, 188) -1\n",
      "2026-01-09 22:30:14,914 - DEBUG - Preprocessing image\n",
      "2026-01-09 22:30:14,918 - DEBUG - key: AirTemp [°C], bounds:(409, 221, 471, 238) -1\n",
      "2026-01-09 22:30:14,920 - DEBUG - Preprocessing image\n",
      "2026-01-09 22:30:14,923 - DEBUG - key: BaromPres [mmHg], bounds:(391, 415, 449, 434) -1\n",
      "2026-01-09 22:30:14,925 - DEBUG - Preprocessing image\n",
      "2026-01-09 22:30:14,932 - DEBUG - key: BaromPres [mB], bounds:(467, 415, 537, 434) -1\n",
      "2026-01-09 22:30:14,934 - DEBUG - Preprocessing image\n",
      "2026-01-09 22:30:14,939 - DEBUG - key: DewPoint [°F], bounds:(505, 322, 552, 341) -1\n",
      "2026-01-09 22:30:14,941 - DEBUG - Preprocessing image\n",
      "2026-01-09 22:30:14,945 - DEBUG - key: DewPoint [°C], bounds:(563, 322, 605, 341) -1\n",
      "2026-01-09 22:30:14,948 - DEBUG - Preprocessing image\n",
      "2026-01-09 22:30:14,952 - DEBUG - key: RelHum [%], bounds:(391, 323, 448, 341) -1\n",
      "2026-01-09 22:30:14,954 - DEBUG - Preprocessing image\n",
      "2026-01-09 22:30:14,960 - DEBUG - key: WindTimestamp, bounds:(100, 64, 294, 78) 4\n",
      "2026-01-09 22:30:14,963 - DEBUG - Preprocessing image\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "BuoyDataCapture.ocr_dates_only() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m obj = BuoyDataCapture(execrocksWind_url, windSources)\n\u001b[32m      5\u001b[39m obj.fetch_image()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_regions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtime: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj[\u001b[33m'\u001b[39m\u001b[33mWindTimestamp\u001b[39m\u001b[33m'\u001b[39m].strftime(\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m%\u001b[39m\u001b[33mI:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS \u001b[39m\u001b[33m%\u001b[39m\u001b[33mP \u001b[39m\u001b[33m%\u001b[39m\u001b[33mZ\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m @\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj[\u001b[33m'\u001b[39m\u001b[33mTimestamp\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m datetime.now(pytz.timezone(\u001b[33m'\u001b[39m\u001b[33mUS/Eastern\u001b[39m\u001b[33m'\u001b[39m)) < obj[\u001b[33m'\u001b[39m\u001b[33mWindTimestamp\u001b[39m\u001b[33m'\u001b[39m]:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 161\u001b[39m, in \u001b[36mBuoyDataCapture.extract_regions\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    157\u001b[39m croppedImage = \u001b[38;5;28mself\u001b[39m.preprocess_for_ocr(img.crop(item[\u001b[33m'\u001b[39m\u001b[33mbounds\u001b[39m\u001b[33m'\u001b[39m]))\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key.find(\u001b[33m\"\u001b[39m\u001b[33mTime\u001b[39m\u001b[33m\"\u001b[39m)>-\u001b[32m1\u001b[39m:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Decoding the date can be tricky. Though the buoys are connected via cell their clocks can be wildly off.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mocr_dates_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcroppedImage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mocrLimits\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdatelike\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m     data += \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m{\u001b[39m\u001b[33mdatetime.now().year}\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m#ATTN: When testing this on Jan 02, 2026 the buoy's clock was 2hrs fast. This may be corrected later.\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: BuoyDataCapture.ocr_dates_only() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "## Time is screwed up but doesn't seem to correct.\n",
    "logging.basicConfig(filename='capture.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "obj = BuoyDataCapture(execrocksWind_url, windSources)\n",
    "obj.fetch_image()\n",
    "obj.extract_regions()\n",
    "\n",
    "print(f\"time: {obj['WindTimestamp'].strftime('%Y-%m-%d %I:%M:%S %P %Z')} @{obj['Timestamp']}  \")\n",
    "\n",
    "if datetime.now(pytz.timezone('US/Eastern')) < obj['WindTimestamp']:\n",
    "    print(\"Why is the time wrong?\")\n",
    "\n",
    "obj.getDict()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "03c56fa9-3424-4256-9ca5-b297a4759cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tWRK: WaveHgtSig [ft]: (68, 329, 112, 346) -1\n",
      "\tWRK: WaveHgtMax [ft]: (168, 329, 212, 346) -1\n",
      "\tWRK: WaveHgtSig [m]: (68, 353, 112, 371) -1\n",
      "\tWRK: WaveHgtMax [m]: (168, 353, 212, 371) -1\n",
      "\tWRK: WaveDir [°]: (292, 322, 347, 340) -1\n",
      "\tWRK: WavPerAvg [s]: (479, 193, 539, 211) -1\n",
      "\tWRK: WavPerDom [s]: (479, 251, 539, 269) -1\n",
      "\tWRK: Timestamp: (100, 64, 294, 78) 0\n",
      "\t\tDBG: time string [raw]: '9:00:00 AM EST, Thu Jan 08, 2026'\n",
      "\t\tDBG: Time is OK\n",
      "time: 2026-01-08 09:00:00 am @2026-01-08 09:00:00-04:56  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'WaveHgtSig [ft]': 0.06,\n",
       " 'WaveHgtMax [ft]': 0.1,\n",
       " 'WaveHgtSig [m]': 0.02,\n",
       " 'WaveHgtMax [m]': 0.03,\n",
       " 'WaveDir [°]': 96.0,\n",
       " 'WavPerAvg [s]': 2.5,\n",
       " 'WavPerDom [s]': 23.0,\n",
       " 'Timestamp': datetime.datetime(2026, 1, 8, 9, 0, tzinfo=<DstTzInfo 'US/Eastern' LMT-1 day, 19:04:00 STD>)}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = WeatherDataRead(execrocksWaves_url, waveSources)\n",
    "obj.fetch_image()\n",
    "obj.extract_regions()\n",
    "\n",
    "print(f\"time: {obj['WaveTimestamp'].strftime('%Y-%m-%d %I:%M:%S %P')} @{obj['WaveTimestamp']}  \")\n",
    "\n",
    "obj.getDict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27283ccb-d1de-4dbd-8dbe-6de6b3020b27",
   "metadata": {},
   "source": [
    "## Data Storage\n",
    "This is essentially a ring buffer of wind and wave data accuulated from Execution Rocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edc6376f-2562-44cf-bd79-fd7d61d6e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "class DataBuffer:\n",
    "    def __init__(self, labels, filepath=\"sensor_data.csv\"):\n",
    "        \"\"\"\n",
    "        :param labels: List of strings for the 12 column names.\n",
    "        :param filepath: Path to the CSV file.\n",
    "        \"\"\"\n",
    "        self.filepath = filepath\n",
    "        self.columns = labels\n",
    "        \n",
    "        if len(self.columns) != len(labels):\n",
    "            raise ValueError(\"There is a mismatch in the number of labels and number of columns.\")\n",
    "\n",
    "        if os.path.exists(self.filepath):\n",
    "            # Load existing data and ensure the index is parsed as datetime\n",
    "            self.df = pd.read_csv(self.filepath, index_col=0, parse_dates=True)\n",
    "            # Ensure index is timezone-aware (UTC) to match new records\n",
    "            if self.df.index.tz is None:\n",
    "                self.df.index = self.df.index.tz_localize(timezone.utc)\n",
    "            # Ensure existing columns match the provided labels\n",
    "            self.df.columns = self.columns\n",
    "        else:\n",
    "            # Initialize empty DataFrame with custom labels and UTC timezone awareness\n",
    "            self.df = pd.DataFrame(columns=self.columns)\n",
    "            self.df.index = pd.to_datetime(self.df.index).tz_localize(timezone.utc)\n",
    "\n",
    "    def add_record(self, data_dict):\n",
    "        \"\"\"\n",
    "        Appends a dictionary to the dataframe in one step.\n",
    "        :param data_dict: Dictionary where keys match self.columns.\n",
    "        \"\"\"\n",
    "        # 1. Create a timezone-aware timestamp for the current moment\n",
    "        now = datetime.now(timezone.utc)\n",
    "        \n",
    "        # 2. Single-step append: loc automatically maps dictionary keys to columns\n",
    "        self.df.loc[now] = data_dict\n",
    "        \n",
    "        # 3. Maintain the 3-day ring buffer and save\n",
    "        self._truncate_and_save()\n",
    "\n",
    "    def _truncate_and_save(self):\n",
    "        \"\"\"Truncates data older than 3 days and saves to CSV to persist through reboots.\"\"\"\n",
    "        cutoff_time = datetime.now(timezone.utc) - timedelta(days=3)\n",
    "        # Keep only records from the last 72 hours\n",
    "        self.df = self.df[self.df.index >= cutoff_time]\n",
    "        self.df.to_csv(self.filepath)\n",
    "\n",
    "    def get_data(self):\n",
    "        \"\"\"Access the dataframe for graphing or analysis.\"\"\"\n",
    "        return self.df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01fbc29-0302-485d-97c3-40e6bca52e84",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Trying to extract the operational indicator\n",
    "\n",
    "xml path to ONLINE:\n",
    "/html/body/center/div/div[2]/div/table/tbody/tr/td[2]/table/tbody/tr/td/table/tbody/tr/td[1]/div[2]/div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27be98b-7ef9-4d25-9ad5-349411e442e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesn't seem to work and besides I am not sure I'd trust the results.\n",
    "\n",
    "import requests\n",
    "from lxml import etree\n",
    "\"\"\"\n",
    "https://lisicos.uconn.edu/stn_wlis.php?id=wlis_wx_panel\n",
    "\n",
    "\"\"\"\n",
    "# 1. Fetch content from the source website\n",
    "url = \"https://lisicos.uconn.edu/stn_wlis.php?id=wlis_wx_panel\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# 2. Parse the XML content\n",
    "# Use response.content (raw bytes) rather than response.text to handle encodings correctly\n",
    "tree = etree.fromstring(response.content)\n",
    "\n",
    "# 3. Fetch the string using a specific XPath\n",
    "# Example: Fetching the text from <root><item><name>Some Text</name></item></root>\n",
    "xpath_query = \"/html/body/center/div/div[2]/div/table/tbody/tr/td[2]/table/tbody/tr/td/table/tbody/tr/td[1]/div[2]/div\"\n",
    "result = tree.xpath(xpath_query)\n",
    "\n",
    "# 4. Display the result\n",
    "if result:\n",
    "    print(f\"Found string: {result[0]}\")\n",
    "else:\n",
    "    print(\"Path not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329d6b24-304e-4493-8d5a-bc118b85dcb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
